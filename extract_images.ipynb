{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import math\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"images\")\n",
    "files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_POINT = 6000\n",
    "MIDZONE_THRESHOLD = 15000\n",
    "MIN_HANDWRITING_HEIGHT_PIXEL = 20\n",
    "\n",
    "BASELINE_ANGLE = 0.0\n",
    "TOP_MARGIN = 0.0\n",
    "LETTER_SIZE = 0.0\n",
    "LINE_SPACING = 0.0\n",
    "WORD_SPACING = 0.0\n",
    "PEN_PRESSURE = 0.0\n",
    "SLANT_ANGLE = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"image = cv2.imread('images/010-0.png', cv2.IMREAD_GRAYSCALE)\\n\\n# Calculate the histogram\\nhistogram = cv2.calcHist([image], [0], None, [256], [0, 256])\\n\\n# Plot the histogram\\nplt.plot(histogram)\\nplt.title('Histogram')\\nplt.xlabel('Pixel Intensity')\\nplt.ylabel('Frequency')\\nplt.show()\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''image = cv2.imread('images/010-0.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Calculate the histogram\n",
    "histogram = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "\n",
    "# Plot the histogram\n",
    "plt.plot(histogram)\n",
    "plt.title('Histogram')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(image, kernalSize):\n",
    "    #  dilation of objects in the image\n",
    "    kernel = np.ones(kernalSize, np.uint8)\n",
    "    image = cv2.dilate(image, kernel, iterations=1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barometer(image):\n",
    "    # extract average pen pressure of the handwriting\n",
    "    global PEN_PRESSURE\n",
    "    #convert to grayscale\n",
    "    gray_image= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # invert image\n",
    "    inverted = cv2.bitwise_not(gray_image)\n",
    "\n",
    "    # bilateral filtering\n",
    "    filtered = cv2.bilateralFilter(inverted, 3, 50, 50)\n",
    "\n",
    "    # binary thresholding\n",
    "    ret, thresh = cv2.threshold(filtered, 100, 255, cv2.THRESH_TOZERO)\n",
    "\n",
    "    # add up all the non-zero pixel values in the image and divide by the number of them to find the average pixel value in the whole image\n",
    "    non_zero_pixels = thresh[thresh > 0]\n",
    "    if len(non_zero_pixels) > 0:\n",
    "        average_intensity = np.sum(non_zero_pixels) / len(non_zero_pixels)\n",
    "    else:\n",
    "        average_intensity = 0  # Default to 0 if no non-zero pixels are found\n",
    "\n",
    "    PEN_PRESSURE = average_intensity\n",
    "    # print (\"PEN_PRESSURE: \"+str(average_intensity))\n",
    "    return\n",
    "\n",
    "#barometer(cv2.imread('images/'+\"000-0.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def straighten(image):\n",
    "    global BASELINE_ANGLE\n",
    "    \n",
    "    angle = 0.0\n",
    "    angle_sum = 0.0\n",
    "    contour_count = 0\n",
    "\n",
    "    # Apply bilateral filter\n",
    "    filtered = cv2.bilateralFilter(image, d=3, sigmaColor=50, sigmaSpace=50)\n",
    "\n",
    "    # Convert to grayscale and binarize with inverted thresholding\n",
    "    gray_image = cv2.cvtColor(filtered, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray_image, 120, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Dilate the lines in the image with a suitable kernel\n",
    "    dilated = dilate(thresh, (5, 100))\n",
    "\n",
    "    # Find contours\n",
    "    ctrs, _ = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    \n",
    "\n",
    "    for i, ctr in enumerate(ctrs):\n",
    "        x, y, w, h = cv2.boundingRect(ctr)\n",
    "\n",
    "        # Skip contours that do not resemble lines\n",
    "        if h > w or h < MIN_HANDWRITING_HEIGHT_PIXEL:\n",
    "            continue\n",
    "\n",
    "        # Extract the region of interest\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "\n",
    "        if w < image.shape[1] / 2:\n",
    "            # If the contour is too narrow, treat it as blank\n",
    "            image[y:y+h, x:x+w] = 255\n",
    "            continue\n",
    "\n",
    "        # Get angle from minAreaRect to straighten the contour\n",
    "        rect = cv2.minAreaRect(ctr)\n",
    "        center = rect[0]\n",
    "        angle = rect[2]\n",
    "\n",
    "        # Adjust angle if it's less than -45 degrees\n",
    "        if angle < -45.0:\n",
    "            angle += 90.0\n",
    "        elif angle > 45:\n",
    "            angle -= 90\n",
    "        \n",
    "\n",
    "        # Rotate the region of interest based on the calculated angle\n",
    "        rot = cv2.getRotationMatrix2D(((x + w) / 2, (y + h) / 2), angle, 1)\n",
    "        straightened = cv2.warpAffine(roi, rot, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255))\n",
    "\n",
    "        \n",
    "\n",
    "        # Place the straightened contour back into the original image\n",
    "        image[y:y+h, x:x+w] = straightened\n",
    "\n",
    "        # Accumulate angles to compute average later\n",
    "        angle_sum += angle\n",
    "        contour_count += 1\n",
    "\n",
    "        \n",
    "    \n",
    "    # if image is not None:  \n",
    "    #         cv2.imshow('image', image)\n",
    "    #         cv2.waitKey(0) \n",
    "    #         cv2.destroyAllWindows()\n",
    "    \n",
    "    # print(\"Angle Sum: \",angle_sum, \" Contour Count: \",contour_count)\n",
    "    # Calculate the mean angle of all contours, ensuring no division by zero\n",
    "    mean_angle = angle_sum / contour_count if contour_count > 0 else angle_sum\n",
    "    BASELINE_ANGLE = mean_angle\n",
    "    # print(\"BASELINE_ANGLE:\", mean_angle)\n",
    "\n",
    "    return image\n",
    "\n",
    "#straighten(cv2.imread('images/'+\"000-10.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LETTER_SIZE:  12.142857142857142\n",
      "LINE_SPACING:  4.435294117647059\n",
      "TOP_MARGIN:  2.635294117647059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[70, 102],\n",
       " [154, 182],\n",
       " [221, 246.5],\n",
       " [298, 329],\n",
       " [371, 401],\n",
       " [440, 467],\n",
       " [515, 538]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractLines(img):\n",
    "    # extract lines of handwritten text from the image using horizontal projection\n",
    "\n",
    "    global LETTER_SIZE\n",
    "    global LINE_SPACING\n",
    "    global TOP_MARGIN\n",
    "\n",
    "    # apply bilateral filter\n",
    "    filtered = cv2.bilateralFilter(img, 5, 50, 50)\n",
    "\n",
    "    #convert to grayscale\n",
    "    gray_image= cv2.cvtColor(filtered, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # convert to grayscale and binarize the image by INVERTED binary thresholding\n",
    "    ret, thresh = cv2.threshold(gray_image, 160, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # if thresh is not None:  \n",
    "    #         cv2.imshow('image', thresh)\n",
    "    #         cv2.waitKey(0) \n",
    "    #         cv2.destroyAllWindows()\n",
    "    # extract a python list containing values of the horizontal projection of the image into 'hp'\n",
    "    #hpList = np.sum(thresh, axis=1).tolist()\n",
    "    hpList = np.sum(thresh , axis=1).tolist()\n",
    "    # plt.plot(hpList)\n",
    "    # plt.xlabel('Row Index')\n",
    "    # plt.ylabel('Pixel Intensity Sum')\n",
    "    # plt.title('Horizontal Projection')\n",
    "    # plt.show()\n",
    "    \n",
    "    # Extracting 'Top Margin' feature.\n",
    "    topMarginCount = 0\n",
    "    for row_sum in hpList:\n",
    "        # If row_sum is 0, we are still in the top margin\n",
    "        if row_sum < 100:\n",
    "            topMarginCount += 1\n",
    "        else:\n",
    "            break\n",
    "    #print(f\"Top Margin: {topMarginCount} pixels\")\n",
    "\n",
    "    # print \"(Top margin row count: \"+str(topMarginCount)+\")\"\n",
    "\n",
    "    # extract the straightened contours from the image by looking at occurance of 0's in the horizontal projection.\n",
    "    lineTop = 0\n",
    "    lineBottom = 0\n",
    "    spaceTop = 0\n",
    "    spaceBottom = 0\n",
    "    indexCount = 0\n",
    "    setLineTop = True\n",
    "    setSpaceTop = True\n",
    "    includeNextSpace = True\n",
    "    space_zero = []  # stores the amount of space between lines\n",
    "    lines = []  # a 2D list storing the vertical start index and end index of each contour\n",
    "\n",
    "    # scanning the whole horizontal projection now\n",
    "    for i, row_sum in enumerate(hpList):\n",
    "        # row_sum being 0 means blank space\n",
    "        if (row_sum == 0):\n",
    "            if (setSpaceTop):\n",
    "                spaceTop = indexCount\n",
    "                setSpaceTop = False  # spaceTop will be set once for each start of a space between lines\n",
    "            indexCount += 1\n",
    "            spaceBottom = indexCount\n",
    "            \n",
    "            if (i < len(hpList) - 1):  # avoid array index out of bounds error\n",
    "                # If the next horizontal projection is 0, keep counting; it's still blank space\n",
    "                if (hpList[i + 1] == 0):\n",
    "                    continue\n",
    "            \n",
    "            # Use this condition if the previous contour is very thin and possibly not a line\n",
    "            if (includeNextSpace):\n",
    "                space_zero.append(spaceBottom - spaceTop)\n",
    "            else:\n",
    "                previous = space_zero.pop() if space_zero else 0\n",
    "                space_zero.append(previous + spaceBottom - lineTop)\n",
    "            \n",
    "            # Next time we encounter 0, it's the beginning of another space, set new spaceTop\n",
    "            setSpaceTop = True\n",
    "\n",
    "        # row_sum greater than 0 means contour\n",
    "        if (row_sum > 0):\n",
    "            if (setLineTop):\n",
    "                lineTop = indexCount\n",
    "                setLineTop = False  # lineTop will be set once for each start of a new line/contour\n",
    "            indexCount += 1\n",
    "            lineBottom = indexCount\n",
    "\n",
    "            if (i < len(hpList) - 1):  # necessary to avoid array index out of bounds error\n",
    "                # If the next horizontal projection is > 0, keep counting; it's still in contour\n",
    "                if (hpList[i + 1] > 0):\n",
    "                    continue\n",
    "\n",
    "                # If the line/contour is too thin (< 20 pixels in height), we ignore it.\n",
    "                if (lineBottom - lineTop < 20):  # Thin contour check\n",
    "                    includeNextSpace = False\n",
    "                    setLineTop = True  # Prepare for next line detection\n",
    "                    continue\n",
    "\n",
    "            # The line/contour is accepted; new space following it will be accepted\n",
    "            includeNextSpace = True\n",
    "\n",
    "            # Append the top and bottom horizontal indices of the line/contour in 'lines'\n",
    "            lines.append([lineTop, lineBottom])\n",
    "            setLineTop = True  # Prepare for the next line detection\n",
    "\n",
    "\n",
    "    # extract the very individual lines from the lines/contours we extracted above.\n",
    "    fineLines = []  # a 2D list storing the horizontal start index and end index of each individual line\n",
    "    for i, line in enumerate(lines):\n",
    "\n",
    "        # anchor will locate the horizontal indices where horizontal projection is > ANCHOR_POINT for uphill or < ANCHOR_POINT for downhill\n",
    "        anchor = line[0]\n",
    "        anchorPoints = []  # python list where the indices obtained by 'anchor' will be stored\n",
    "        # it implies that we expect to find the start of an individual line (vertically), climbing up the histogram\n",
    "        upHill = True\n",
    "        # it implies that we expect to find the end of an individual line (vertically), climbing down the histogram\n",
    "        downHill = False\n",
    "        # we put the region of interest of the horizontal projection of each contour here\n",
    "        segment = hpList[line[0]:line[1]]\n",
    "\n",
    "        for j, sum in enumerate(segment):\n",
    "            if (upHill):\n",
    "                if (sum < ANCHOR_POINT):\n",
    "                    anchor += 1\n",
    "                    continue\n",
    "                anchorPoints.append(anchor)\n",
    "                upHill = False\n",
    "                downHill = True\n",
    "            if (downHill):\n",
    "                if (sum > ANCHOR_POINT):\n",
    "                    anchor += 1\n",
    "                    continue\n",
    "                anchorPoints.append(anchor)\n",
    "                downHill = False\n",
    "                upHill = True\n",
    "\n",
    "\n",
    "        # we can ignore the contour here\n",
    "        if (len(anchorPoints) < 2):\n",
    "            continue\n",
    "\n",
    "        # len(anchorPoints) > 3 meaning contour composed of multiple lines\n",
    "        lineTop = line[0]\n",
    "        for x in range(1, len(anchorPoints)-1, 2):\n",
    "            # 'lineMid' is the horizontal index where the segmentation will be done\n",
    "            lineMid = (anchorPoints[x]+anchorPoints[x+1])/2\n",
    "            lineBottom = lineMid\n",
    "            # line having height of pixels <20 is considered defects, so we just ignore it\n",
    "            # this is a weakness of the algorithm to extract lines (anchor value is ANCHOR_POINT, see for different values!)\n",
    "            if (lineBottom-lineTop < 20):\n",
    "                continue\n",
    "            fineLines.append([lineTop, lineBottom])\n",
    "            lineTop = lineBottom\n",
    "        if (line[1]-lineTop < 20):\n",
    "            continue\n",
    "        fineLines.append([lineTop, line[1]])\n",
    "\n",
    "    # LINE SPACING and LETTER SIZE will be extracted here\n",
    "    # We will count the total number of pixel rows containing upper and lower zones of the lines and add the space_zero/runs of 0's(excluding first and last of the list ) to it.\n",
    "    # We will count the total number of pixel rows containing midzones of the lines for letter size.\n",
    "    # For this, we set an arbitrary (yet suitable!) threshold MIDZONE_THRESHOLD = 15000 in horizontal projection to identify the midzone containing rows.\n",
    "    # These two total numbers will be divided by number of lines (having at least one row>MIDZONE_THRESHOLD) to find average line spacing and average letter size.\n",
    "\n",
    "    space_nonzero_row_count = 0\n",
    "    midzone_row_count = 0\n",
    "    lines_having_midzone_count = 0\n",
    "    flag = False\n",
    "\n",
    "    for i, line in enumerate(fineLines):\n",
    "        # Convert indices to integers if they are not already\n",
    "        line_start = int(line[0])  # Convert start index to integer\n",
    "        line_end = int(line[1])    # Convert end index to integer\n",
    "\n",
    "        # Check if indices are within bounds\n",
    "        if line_start < 0 or line_end >= len(hpList):\n",
    "            print(f\"Warning: Line indices {line_start}:{line_end} are out of bounds for hpList.\")\n",
    "            continue  # Skip this iteration if indices are invalid\n",
    "\n",
    "        segment = hpList[line_start:line_end]  # Extract the relevant segment from hpList\n",
    "        for j, row_sum in enumerate(segment):\n",
    "            if (row_sum < MIDZONE_THRESHOLD):\n",
    "                space_nonzero_row_count += 1\n",
    "            else:\n",
    "                midzone_row_count += 1\n",
    "                flag = True\n",
    "\n",
    "        # This line has contributed at least one count of pixel row of midzone\n",
    "        if flag:\n",
    "            lines_having_midzone_count += 1\n",
    "            flag = False  # Reset flag for the next line\n",
    "\n",
    "    # Error prevention\n",
    "    if (lines_having_midzone_count == 0):\n",
    "        lines_having_midzone_count = 1  # Ensure at least 1 if none found\n",
    "\n",
    "\n",
    "\n",
    "    # excluding first and last entries: Top and Bottom margins\n",
    "    total_space_row_count = space_nonzero_row_count + np.sum(space_zero[1:-1])\n",
    "    # the number of spaces is 1 less than number of lines but total_space_row_count contains the top and bottom spaces of the line\n",
    "    average_line_spacing = float(\n",
    "        total_space_row_count) / lines_having_midzone_count\n",
    "    average_letter_size = float(midzone_row_count) / lines_having_midzone_count\n",
    "    # letter size is actually height of the letter and we are not considering width\n",
    "    LETTER_SIZE = average_letter_size\n",
    "    # error prevention ^-^\n",
    "    if (average_letter_size == 0):\n",
    "        average_letter_size = 1\n",
    "    # We can't just take the average_line_spacing as a feature directly. We must take the average_line_spacing relative to average_letter_size.\n",
    "    # Let's take the ratio of average_line_spacing to average_letter_size as the LINE SPACING, which is perspective to average_letter_size.\n",
    "    relative_line_spacing = average_line_spacing / average_letter_size\n",
    "    LINE_SPACING = relative_line_spacing\n",
    "\n",
    "    # Top marging is also taken relative to average letter size of the handwritting\n",
    "    relative_top_margin = float(topMarginCount) / average_letter_size\n",
    "    TOP_MARGIN = relative_top_margin\n",
    "\n",
    "    print(\"LETTER_SIZE: \",LETTER_SIZE)\n",
    "    print(\"LINE_SPACING: \",LINE_SPACING)\n",
    "    print(\"TOP_MARGIN: \",TOP_MARGIN)\n",
    "\n",
    "    \n",
    "    return fineLines\n",
    "\n",
    "extractLines(straighten(cv2.imread('images/'+\"000-0.png\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWords(image, lines):\n",
    "\n",
    "    global LETTER_SIZE\n",
    "    global WORD_SPACING\n",
    "\n",
    "    # apply bilateral filter\n",
    "    filtered = cv2.bilateralFilter(image, 5, 50, 50)\n",
    "\n",
    "    #convert to grayscale\n",
    "    gray_image= cv2.cvtColor(filtered, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # convert to grayscale and binarize the image by INVERTED binary thresholding\n",
    "    ret, thresh = cv2.threshold(gray_image, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Width of the whole document is found once.\n",
    "    width = thresh.shape[1]\n",
    "    space_zero = []  # stores the amount of space between words\n",
    "    words = []  # a 2D list storing the coordinates of each word: y1, y2, x1, x2\n",
    "\n",
    "    # Isolated words or components will be extacted from each line by looking at occurance of 0's in its vertical projection.\n",
    "    for i, line in enumerate(lines):\n",
    "        # Ensure line values and width are integers\n",
    "        y1, y2 = int(line[0]), int(line[1])  # Use int() instead of float()\n",
    "        extract = thresh[y1:y2, 0:int(width)]  # y1:y2, x1:x2\n",
    "\n",
    "        # Compute vertical projection on the extracted segment\n",
    "        vp = np.sum(extract, axis=0).tolist()\n",
    "        \n",
    "\n",
    "        wordStart = 0\n",
    "        wordEnd = 0\n",
    "        spaceStart = 0\n",
    "        spaceEnd = 0\n",
    "        indexCount = 0\n",
    "        setWordStart = True\n",
    "        setSpaceStart = True\n",
    "        includeNextSpace = True\n",
    "        spaces = []\n",
    "\n",
    "        # we are scanning the vertical projection\n",
    "        for j, sum in enumerate(vp):\n",
    "            # sum being 0 means blank space\n",
    "            if (sum == 0):\n",
    "                if (setSpaceStart):\n",
    "                    spaceStart = indexCount\n",
    "                    # spaceStart will be set once for each start of a space between lines\n",
    "                    setSpaceStart = False\n",
    "                indexCount += 1\n",
    "                spaceEnd = indexCount\n",
    "                if (j < len(vp)-1):  # this condition is necessary to avoid array index out of bound error\n",
    "                    # if the next vertical projectin is 0, keep on counting, it's still in blank space\n",
    "                    if (vp[j+1] == 0):\n",
    "                        continue\n",
    "\n",
    "                # we ignore spaces which is smaller than half the average letter size\n",
    "                if ((spaceEnd-spaceStart) > int(LETTER_SIZE/2)):\n",
    "                    spaces.append(spaceEnd-spaceStart)\n",
    "\n",
    "                # next time we encounter 0, it's begining of another space so we set new spaceStart\n",
    "                setSpaceStart = True\n",
    "\n",
    "            # sum greater than 0 means word/component\n",
    "            if (sum > 0):\n",
    "                if (setWordStart):\n",
    "                    wordStart = indexCount\n",
    "                    setWordStart = False  # wordStart will be set once for each start of a new word/component\n",
    "                indexCount += 1\n",
    "                wordEnd = indexCount\n",
    "                if (j < len(vp)-1):  # this condition is necessary to avoid array index out of bound error\n",
    "                    # if the next horizontal projectin is > 0, keep on counting, it's still in non-space zone\n",
    "                    if (vp[j+1] > 0):\n",
    "                        continue\n",
    "\n",
    "                # append the coordinates of each word/component: y1, y2, x1, x2 in 'words'\n",
    "                # we ignore the ones which has height smaller than half the average letter size\n",
    "                # this will remove full stops and commas as an individual component\n",
    "                count = 0\n",
    "                line_start = int(line[0])\n",
    "                line_end = int(line[1])\n",
    "\n",
    "                for k in range(line_end - line_start):\n",
    "                    row = thresh[line_start + k:line_start + k + 1, wordStart:wordEnd]  # y1:y2, x1:x2\n",
    "                    if np.sum(row):\n",
    "                        count += 1\n",
    "\n",
    "                if count > int(LETTER_SIZE / 2):\n",
    "                    words.append([line_start, line_end, wordStart, wordEnd])\n",
    "\n",
    "                # Next time we encounter value > 0, it's the beginning of another word/component, so we set a new wordStart\n",
    "                setWordStart = True\n",
    "\n",
    "\n",
    "        space_zero.extend(spaces[1:-1])\n",
    "\n",
    "    # print space_zero\n",
    "    space_columns = np.sum(space_zero)\n",
    "    space_count = len(space_zero)\n",
    "    if (space_count == 0):\n",
    "        space_count = 1\n",
    "    average_word_spacing = float(space_columns) / space_count\n",
    "    if LETTER_SIZE == 0.0:\n",
    "        relative_word_spacing = average_word_spacing\n",
    "    else:\n",
    "        relative_word_spacing = average_word_spacing / LETTER_SIZE\n",
    "    # used to be divideed but LETTER_SIZE\n",
    "    WORD_SPACING = relative_word_spacing\n",
    "    # print (\"Average word spacing: \"+str(average_word_spacing))\n",
    "    # print (\"Average word spacing relative to average letter size: \"+str(relative_word_spacing))\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSlant(img, words):\n",
    "\n",
    "    global SLANT_ANGLE\n",
    "\n",
    "    if not words:\n",
    "        return 0  # or an appropriate error value\n",
    "\n",
    "    # 9 different values of angle\n",
    "    \n",
    "    theta = [-0.785398, -0.523599, -0.261799, -0.0872665,\n",
    "             0.01, 0.0872665, 0.261799, 0.523599, 0.785398]\n",
    "\n",
    "    # Corresponding index of the biggest value in s_function will be the index of the most likely angle in 'theta'\n",
    "    s_function = [0.0] * 9\n",
    "    count_ = [0]*9\n",
    "\n",
    "    # apply bilateral filter\n",
    "    filtered = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "\n",
    "    #convert to grayscale\n",
    "    gray_image= cv2.cvtColor(filtered, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # convert to grayscale and binarize the image by INVERTED binary thresholding\n",
    "    ret, thresh = cv2.threshold(gray_image, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # loop for each value of angle in theta\n",
    "    for i, angle in enumerate(theta):\n",
    "        s_temp = 0.0  # overall sum of the functions of all the columns of all the words!\n",
    "        count = 0  # just counting the number of columns considered to contain a vertical stroke and thus contributing to s_temp\n",
    "\n",
    "        # loop for each word\n",
    "        for j, word in enumerate(words):\n",
    "            original = thresh[word[0]:word[1], word[2]:word[3]]  # y1:y2, x1:x2\n",
    "            \n",
    "            height, width = original.shape\n",
    "            # height = word[1]-word[0]\n",
    "            # width = word[3]-word[2]\n",
    "\n",
    "            # the distance in pixel we will shift for affine transformation\n",
    "            # it's divided by 2 because the uppermost point and the lowermost points are being equally shifted in opposite directions\n",
    "            shift = (math.tan(angle) * height) / 2\n",
    "\n",
    "            # the amount of extra space we need to add to the original image to preserve information\n",
    "            # yes, this is adding more number of columns but the effect of this will be negligible\n",
    "            pad_length = abs(int(shift))\n",
    "\n",
    "            # create a new image that can perfectly hold the transformed and thus widened image\n",
    "            # blank_image = np.zeros((height, width+pad_length*2, 3), np.uint8)\n",
    "            # new_image = cv2.cvtColor(blank_image, cv2.COLOR_BGR2GRAY)\n",
    "            # new_image[:, pad_length:width+pad_length] = original\n",
    "\n",
    "            new_image = np.pad(original, ((0, 0), (pad_length, pad_length)), mode='constant', constant_values=0)\n",
    "\n",
    "            # points to consider for affine transformation\n",
    "            (height, width) = new_image.shape[:2]\n",
    "            x1 = width/2\n",
    "            y1 = 0\n",
    "            x2 = width/4\n",
    "            y2 = height\n",
    "            x3 = 3*width/4\n",
    "            y3 = height\n",
    "\n",
    "            pts1 = np.float32([[x1, y1], [x2, y2], [x3, y3]])\n",
    "            pts2 = np.float32([[x1+shift, y1], [x2-shift, y2], [x3-shift, y3]])\n",
    "\n",
    "            \n",
    "            M = cv2.getAffineTransform(pts1, pts2)\n",
    "            #deslanted = cv2.warpAffine(new_image, M, (width, height))\n",
    "            deslanted = cv2.warpAffine(new_image, M, (new_image.shape[1], height), borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "\n",
    "            # find the vertical projection on the transformed image\n",
    "            vp = np.sum(deslanted, axis=0)\n",
    "            \n",
    "\n",
    "            # loop for each value of vertical projection, which is for each column in the word image\n",
    "            for k, col_value in enumerate(vp):\n",
    "                # the columns is empty\n",
    "                if (col_value == 0):\n",
    "                    continue\n",
    "\n",
    "                # this is the number of foreground pixels in the column being considered\n",
    "                num_fgpixel = col_value / 255\n",
    "\n",
    "                # if number of foreground pixels is less than onethird of total pixels, it is not a vertical stroke so we can ignore\n",
    "                if (num_fgpixel < height/3):\n",
    "                    continue\n",
    "\n",
    "                # the column itself is extracted, and flattened for easy operation\n",
    "                # column = deslanted[0:height, k:k+1]\n",
    "                # column = column.flatten()\n",
    "\n",
    "                # # now we are going to find the distance between topmost pixel and bottom-most pixel\n",
    "                # # l counts the number of empty pixels from top until and upto a foreground pixel is discovered\n",
    "                # for l, pixel in enumerate(column):\n",
    "                #     if (pixel == 0):\n",
    "                #         continue\n",
    "                #     break\n",
    "                # # m counts the number of empty pixels from bottom until and upto a foreground pixel is discovered\n",
    "                # for m, pixel in enumerate(column[::-1]):\n",
    "                #     if (pixel == 0):\n",
    "                #         continue\n",
    "                #     break\n",
    "\n",
    "                # # the distance is found as delta_y, I just followed the naming convention in the research paper I followed\n",
    "                # delta_y = height - (l+m)\n",
    "\n",
    "                top_pixel = next(i for i, px in enumerate(deslanted[:, k]) if px != 0)\n",
    "                bottom_pixel = next(i for i, px in enumerate(deslanted[:, k][::-1]) if px != 0)\n",
    "                \n",
    "                delta_y = height - (top_pixel + bottom_pixel)\n",
    "\n",
    "                # h_sq = (float(num_fgpixel)/delta_y)**2\n",
    "\n",
    "                # # multiplying by a factor of num_fgpixel/height to the above function to yeild better result\n",
    "                # # this will also somewhat negate the effect of adding more columns and different column counts in the transformed image of the same word\n",
    "                # h_wted = (h_sq * num_fgpixel) / height\n",
    "\n",
    "\n",
    "                # # add up the values from all the loops of ALL the columns of ALL the words in the image\n",
    "                # s_temp += h_wted\n",
    "\n",
    "                h_sq = (num_fgpixel / delta_y) ** 2\n",
    "                s_temp += h_sq * num_fgpixel / height\n",
    "                count += 1\n",
    "\n",
    "                count += 1\n",
    "\n",
    "        s_function[i] = s_temp / count if count > 0 else 0\n",
    "        count_[i] = count\n",
    "\n",
    "    # finding the largest value and corresponding index\n",
    "    max_value = 0.0\n",
    "    max_index = 4\n",
    "    # for index, value in enumerate(s_function):\n",
    "    #     # print str(index)+\" \"+str(value)+\" \"+str(count_[index])\n",
    "    #     if (value > max_value):\n",
    "    #         max_value = value\n",
    "    #         max_index = index\n",
    "    \n",
    "    for index, value in enumerate(s_function):\n",
    "        if value > max_value:\n",
    "            max_value = value\n",
    "            max_index = index  # Capture the index of the new max value\n",
    "\n",
    "    if max_index != -1:\n",
    "        angle = math.degrees(theta[max_index])\n",
    "\n",
    "    print(\"Max Index: \",max_index, \"Angle: \",angle)\n",
    "\n",
    "    # add another value 9 manually to indicate irregular slant behaviour.\n",
    "    # This will be seen as value 4 (no slant) but 2 corresponding angles of opposite sign will have very close values.\n",
    "    if (max_index == 0):\n",
    "        angle = 45\n",
    "        result = \" : Extremely right slanted\"\n",
    "    elif (max_index == 1):\n",
    "        angle = 30\n",
    "        result = \" : Above average right slanted\"\n",
    "    elif (max_index == 2):\n",
    "        angle = 15\n",
    "        result = \" : Average right slanted\"\n",
    "    elif (max_index == 3):\n",
    "        angle = 5\n",
    "        result = \" : A little right slanted\"\n",
    "    elif (max_index == 5):\n",
    "        angle = -5\n",
    "        result = \" : A little left slanted\"\n",
    "    elif (max_index == 6):\n",
    "        angle = -15\n",
    "        result = \" : Average left slanted\"\n",
    "    elif (max_index == 7):\n",
    "        angle = -30\n",
    "        result = \" : Above average left slanted\"\n",
    "    elif (max_index == 8):\n",
    "        angle = -45\n",
    "        result = \" : Extremely left slanted\"\n",
    "    elif (max_index == 4):\n",
    "        if s_function[3] == 0.0:\n",
    "            p = s_function[4]  # / s_function[3]\n",
    "            q = s_function[4]  # / s_function[5]\n",
    "        else:\n",
    "            p = s_function[4] / s_function[3]\n",
    "            q = s_function[4] / s_function[5]\n",
    "        # print 'p='+str(p)+' q='+str(q)\n",
    "        if ((p <= 1.2 and q <= 1.2) or (p > 1.4 and q > 1.4)):\n",
    "            angle = 0\n",
    "            result = \" : No slant\"\n",
    "        elif ((p <= 1.2 and q-p > 0.4) or (q <= 1.2 and p-q > 0.4)):\n",
    "            angle = 0\n",
    "            result = \" : No slant\"\n",
    "        else:\n",
    "            max_index = 9\n",
    "            angle = 180\n",
    "            result = \" : Irregular slant behaviour\"\n",
    "\n",
    "        if angle == 0:\n",
    "            print(\"\\n************************************************\")\n",
    "            print(\"Slant determined to be straight.\")\n",
    "        else:\n",
    "            print(\"\\n************************************************\")\n",
    "            print(\"Slant determined to be irregular.\")\n",
    "        # type = input(\"Press enter if okay, else enter c to change: \")\n",
    "        # if type == 'c':\n",
    "        #     if angle == 0:\n",
    "        #         angle = 180\n",
    "        #         result = \" : Irregular Slant\"\n",
    "        #         print(\"Set as\"+result)\n",
    "        #         print(\"************************************************\\n\")\n",
    "        #     else:\n",
    "        #         angle = 0\n",
    "        #         result = \" : Straight/No Slant\"\n",
    "        #         print(\"Set as\"+result)\n",
    "        #         print(\"************************************************\\n\")\n",
    "        # else:\n",
    "        #     print(\"No Change!\")\n",
    "        #     print(\"************************************************\\n\")\n",
    "\n",
    "    SLANT_ANGLE = angle\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LETTER_SIZE:  13.666666666666666\n",
      "LINE_SPACING:  3.048780487804878\n",
      "TOP_MARGIN:  3.073170731707317\n",
      "Max Index:  6 Angle:  14.99997778074544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19, 3.07, 13.67, 3.05, 1.98, 164.55, -15]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def start(file_name):\n",
    "    global BASELINE_ANGLE\n",
    "    global TOP_MARGIN\n",
    "    global LETTER_SIZE\n",
    "    global LINE_SPACING\n",
    "    global WORD_SPACING\n",
    "    global PEN_PRESSURE\n",
    "    global SLANT_ANGLE\n",
    "    \n",
    "    image = cv2.imread('images/'+file_name) \n",
    "\n",
    "    #Pen Pressure\n",
    "    barometer(image)\n",
    "\n",
    "    # straightened image without filtration and binarization\n",
    "    straightened = straighten(image)\n",
    "\n",
    "    # extract lines of handwritten text from the image using the horizontal projection\n",
    "    lineIndices = extractLines(straightened)\n",
    "\n",
    "    # extract words from each line using vertical projection\n",
    "    wordCoordinates = extractWords(straightened, lineIndices)\n",
    "\n",
    "    # extract average slant angle of all the words containing a long vertical stroke\n",
    "    extractSlant(straightened, wordCoordinates)\n",
    "\n",
    "    BASELINE_ANGLE = round(BASELINE_ANGLE, 2)\n",
    "    TOP_MARGIN = round(TOP_MARGIN, 2)\n",
    "    LETTER_SIZE = round(LETTER_SIZE, 2)\n",
    "    LINE_SPACING = round(LINE_SPACING, 2)\n",
    "    WORD_SPACING = round(WORD_SPACING, 2)\n",
    "    PEN_PRESSURE = round(PEN_PRESSURE, 2)\n",
    "    SLANT_ANGLE = round(SLANT_ANGLE, 2)\n",
    "\n",
    "    return [BASELINE_ANGLE, TOP_MARGIN, LETTER_SIZE, LINE_SPACING, WORD_SPACING, PEN_PRESSURE, SLANT_ANGLE]\n",
    "\n",
    "start(\"000-34.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: raw_feature_list already exists.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "page_ids = []\n",
    "if os.path.isfile(\"raw_feature_list\"):\n",
    "    print(\"Info: raw_feature_list already exists.\")\n",
    "    with open(\"raw_feature_list\", \"r\") as label:\n",
    "        for line in label:\n",
    "            content = line.split()\n",
    "            page_id = content[-1]\n",
    "            page_ids.append(page_id)\n",
    "\n",
    "with open(\"raw_feature_list\", \"a\") as label:\n",
    "    count = len(page_ids)\n",
    "    for file_name in files:\n",
    "        if (file_name in page_ids):\n",
    "            continue\n",
    "        features = start(file_name)\n",
    "        features.append(file_name)\n",
    "        for i in features:\n",
    "            label.write(f\"{i}\\t\")\n",
    "        label.write(\"\\n\")\n",
    "        count += 1\n",
    "        progress = (count*100)/len(files)\n",
    "        print (str(count)+' '+file_name+' '+str(progress)+'%')\n",
    "    print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
